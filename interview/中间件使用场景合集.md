# 中间件使用场景合集

## MySQL

最基本的组件，各种数据的持久化存储。

华泰MySQL默认配置RC隔离级别 + binlog_format = row，适用于高并发场景，平衡了性能与一致性

- 无间隙锁，降低锁竞争和死锁
- 提前释放不满足条件的行锁，提高并发度
- 记录行数据变更而非SQL语句，避免主从复制因SQL执行顺序导致的数据不一致问题

## Redis

### 分布式锁

- 定时任务控制，后台微服务多节点部署，执行定时任务时需要抢占分布式锁，避免多节点重复执行定时任务

- 本地缓存刷新时，某些配置项需要频繁读数据库，并具有一定计算量，通过分布式锁控制单线程去获取，避免对数据库造成压力，并且降低cpu开销。其他线程则自旋一段时间（自旋失败抛出异常）

### 分布式缓存

- 加速访问，将部分数据缓存到redis。缓存数据可能包含数据库查询返回的直接结果，或经过计算处理结果
  - 响应速度：Mysql在`ms`级，redis在`μs`级
- 缓存高频数据，降低数据库压力

## Kafka

### 通过注解配置消费者

```java
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

@Component
public class KafkaConsumer {

    @KafkaListener(
      	topics = "my-topic", 
      	groupId = "my-group", 
      	properties = {
        "auto.offset.reset=earliest",
        "max.poll.interval.ms=5000"
        }
    )
    public void listen(String message) {
        System.out.println("Received Message: " + message);
    }
}
```

#### 位移提交

通过`spring.kafka.listener.ack-mode`配置 或 通过`org.springframework.kafka.listener.config.ContainerProperties#ackMode`配置

|          模式          |                       行为                       |          适用场景          |
| :--------------------: | :----------------------------------------------: | :------------------------: |
|      **`RECORD`**      |          每条消息处理成功后立即提交位移          |     高可靠性，但性能低     |
|  **`BATCH`**（默认）   |     批量处理完成后提交位移（攒一批提交一次）     |     平衡可靠性和吞吐量     |
|       **`TIME`**       |      按时间间隔提交位移（需配置 `ackTime`）      |   允许少量重复，提高吞吐   |
|      **`COUNT`**       |  按处理的消息数量提交位移（需配置 `ackCount`）   | 类似 `BATCH`，但按条数控制 |
|      **`MANUAL`**      | 用户手动调用 `Acknowledgment.acknowledge()` 提交 |      完全控制提交时机      |
| **`MANUAL_IMMEDIATE`** |           手动调用后立即提交（非批量）           |     需低延迟手动提交时     |

```java
@KafkaListener(topics = "my-topic", groupId = "my-group")
public void listen(String message, Acknowledgment ack) {
    try {
        System.out.println("Processing: " + message);
        // 业务逻辑...
        ack.acknowledge();  // 手动提交位移
    } catch (Exception e) {
        // 处理异常（不提交位移，会触发重试）
    }
}
```

### 订阅新闻主题拉取新闻

```properties
bootstrap.servers = "***"
topics = "***"
group.id = "***"
enable.auto.commit = true
security.protocol = "SASL_PLAINTEXT"
sasl.mechanism = "SCRM-SHA-512"
sasl.jaas.config = "username password"
```

### 安全日志上报

```properties
bootstrap.servers = "***"
acks = 1 # 仅主副本确认即可
retries = 1 # 不做过多重试，影响性能
batch.size = 32768 # 32KB
compress.type = gzip # CPU开销大、压缩率高，对带宽影响小，但增加了延时
linger.ms = 5 # 等待5ms
```

## Zookeeper

### [elastic job](#elastic job)分布式定时任务管理

### Dubbo服务注册

## Apollo

### 配置管理

携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置。底层依赖于MySQL存储数据

```java
// 定时任务配置
@Async
@Schedule(cron = "${quater.task.xxx:0 0 3 * * ?}")
private void xxx(){...}

// 密钥配置
@Value("${xxx.secret}")
private String secret;
```

#### 热更新

修改配置后1秒内推送到所有应用实例，无需重启服务

## 微服务网关

Http > Dubbo转换

- 统一入口，隔离区 > 核心区
- 请求路由到微服务
- 流量控制、负载均衡
- 协议转换Http > Dubbo
- 请求/响应改写
- 认证与鉴权

## Nginx

- 统一入口，实现负载均衡
- 路由不同应用的微服务
- 反向代理，隐藏后端服务
- 静态资源托管 -> apisix改造后前端改用MinIO部署（一个高性能的分布式对象存储系统）

## S3协议存储网关

## 其他

### 本地缓存 Caffeine

Caffeine 是一个高性能的 Java 本地缓存库，其核心源码设计围绕 **高效缓存管理** 和 **低竞争并发控制** 展开

- 缓存更新频率低，能容忍延迟的数据，如配置项或人员部门等信息
- 加速访问，本地内存读速度极快

```java
Cache<String, Object> cache = new Caffeine.newBuilder()
  	.maximunSize(1000) // 最多1000个元素
  	.expireAfterWrite(12, TimeUnit.HOURS) // 写入的本地缓存12小时后过期
  	.build();

// 自动刷新（校验时机，get()时）
LoadingCache<String, String> cache = Caffeine.newBuilder()
    .refreshAfterWrite(5, TimeUnit.SECONDS)  // 5秒后异步刷新
    .expireAfterWrite(30, TimeUnit.SECONDS)  // 30秒后强制过期
    .build(key -> fetchDataFromDB(key)); // 设置缓存刷新方法
```

#### 关键优化

- 并发

  - 使用`ConcurrentHashMap` 分段存储数据，提升并发性能
  - MPSC（多生产者单消费者）队列：读写中涉及的维护任务（如频率统计、淘汰检测、数据分区调整等）通过 `ReadBuffer`/`WriteBuffer` 缓冲，交由异步线程处理，减少锁竞争
  - 异步刷新缓存，不阻塞请求

- 数据淘汰（异步）

  - Window-TinyLFU：综合LRU、LFU的优势

    - 窗口缓存（Window Cache）：
      占缓存总容量的1%，采用LRU策略，用于临时存储新访问的数据，应对突发流量
    - 主缓存（Main Cache）：占99%容量，分为两个区域：
      - Probation区（试用区，20%）：新晋升的数据需与其他候选数据竞争。
      - Protected区（保护区，80%）：长期高频数据，避免被短期波动淘汰
    - **频率统计**
      - 使用4位计数器（最大15）和多个哈希函数近似统计访问频率，大幅降低内存开销
      - 当计数器总和达到阈值时，所有计数器减半，防止旧数据长期占据缓存

  - ```java
    // 频率统计核心源码
    BoundedLocalCache.this.frequencySketch().increment(key);
    ->
    public void increment(E e) {
        if (!this.isNotInitialized()) {
            int[] index = new int[8];
            int blockHash = spread(e.hashCode());
            int counterHash = rehash(blockHash);
            int block = (blockHash & this.blockMask) << 3;
    
            for(int i = 0; i < 4; ++i) {
                int h = counterHash >>> (i << 3);
                index[i] = h >>> 1 & 15;
                int offset = h & 1;
                index[i + 4] = block + offset + (i << 1);
            }
    				// 尝试对这几个位置 + 1
            boolean added = this.incrementAt(index[4], index[0]) | 
              this.incrementAt(index[5], index[1]) | 
              this.incrementAt(index[6], index[2]) | 
              this.incrementAt(index[7], index[3]);
            if (added && ++this.size == this.sampleSize) {
                this.reset(); // 总访问频率达到一定次数后，所有计数器减半（防止溢出）
            }
        }
    }
    ```

#### 其他选型对比

|      特性      |          Caffeine           |    Guava Cache     |         Ehcache          |
| :------------: | :-------------------------: | :----------------: | :----------------------: |
|    **性能**    |     最高（15M ops/sec）     |  中等（基于LRU）   |  较低（支持磁盘持久化）  |
|  **缓存算法**  | Window-TinyLFU（98%命中率） |        LRU         |         LRU/FIFO         |
|  **并发支持**  |    分段锁优化（高并发）     |     基础锁机制     |       有限并发支持       |
|  **过期策略**  |       时间/容量/引用        |     时间/容量      |   时间/容量/磁盘持久化   |
|  **异步加载**  |            支持             | 支持（需手动实现） |          不支持          |
| **分布式扩展** |           不支持            |       不支持       | 支持（需集成Terracotta） |
|  **适用场景**  |       高并发单机应用        |    简单本地缓存    |   需持久化或企业级缓存   |

### elastic job

当当网开源的分布式调度解决方案，基于 Quartz 二次开发，主要用于解决分布式环境下的定时任务扩展性、高可用及弹性调度问题

- 分片机制（需手动在任务中根据分片号、分片参数实现）
  - 任务可拆分为多个分片，由不同节点处理
- 弹性调度
  - 节点增减时，自动触发分片重分配
  - 节点宕机后，未完成的分片由其他节点接管
- 分布式协调
  - 通过 Zookeeper 选举主节点，负责分片分配和状态同步
  - 利用 Zookeeper 的 Watcher 机制监听节点变化，实时调整任务分配



```java
// 可分片的任务示例
@Component("testJob")
public class TestJob implements SimpleJob {
    @Override
    public void execute(ShardingContext shardingContext) {
        int shardingItem = shardingContext.getShardingItem();
        String shardingParameter = shardingContext.getShardingParameter();
        System.out.printf("current thread is %s, shardingItem is %d, shardingParameter %s\n",
                Thread.currentThread().getName(),
                shardingItem,
                shardingParameter);
    }
}

// 配置定时任务
@Configuration
public class SimpleJobConfig {

    @Resource
    private ZookeeperRegistryCenter zookeeperRegistryCenter;

    @Bean(initMethod = "schedule")
    public ScheduleJobBootstrap scheduleJobBootstrap(@Qualifier("testJob") SimpleJob simpleJob){
        return new ScheduleJobBootstrap(
                zookeeperRegistryCenter,
                simpleJob,
                JobConfiguration.newBuilder("jonName", 3)
                        .shardingItemParameters("0=A,1=B,2=C")
                        .cron("0/10 * * * * ?")
                        .overwrite(true)
                        .build()
        );
    }
}
```

#### 核心代码

- zookeeper

  - ```java
    // 连接zookeeper ip端口，并指定namespace
    ZookeeperConfiguration zookeeperConfiguration = new ZookeeperConfiguration("127.0.0.1:2181", "test");
    ```

  - ```java
    //连接zookeeper时创建临时顺序节点，抢占主节点身份（以任务为维度）
    this.client.create().creatingParentContainersIfNeeded()
      	.withProtection()
      	.withMode(CreateMode.EPHEMERAL_SEQUENTIAL))// 临时顺序节点
      	.inBackground(callback))
      	.forPath(ZKPaths.makePath(this.latchPath, "latch-"), LeaderSelector.getIdBytes(this.id));
    ```

  - ```java
    // 注册各种监听器，如主节点宕机等
    this.listenerManager.startAllListeners();
    ```

  - ```java
    // 注册当前服务器（应用程序实例）的元数据到zk，表示可以参与任务调度管理       
    this.jobNodeStorage.fillJobNode(
      this.serverNode.getServerNode(JobRegistry.getInstance().getJobInstance(this.jobName).getServerIp()),
      enabled ? ServerStatus.ENABLED.name() : ServerStatus.DISABLED.name()
    );
    
    // 注册当前任务实例到zk的临时节点，表示已上线并可以参与任务分配
    this.jobNodeStorage.fillEphemeralJobNode(
      	this.instanceNode.getLocalInstancePath(), // 当前任务实例在zk的路径
      	this.instanceNode.getLocalInstanceValue()
    );
    ```

- elastic job实例

  - ```java
    // 创建调度器（调用factory创建，所有任务共用，如已有则直接返回）
    private Scheduler createScheduler() {
      ...
      StdSchedulerFactory factory = new StdSchedulerFactory();
      factory.initialize(this.getQuartzProps());// 设置线程池参数
      Scheduler result = factory.getScheduler();// 创建Quartz调度器
      ...
        
      // 初始化执行线程池（默认10个线程）
      tp = (ThreadPool) loadHelper.loadClass(tpClass).getDeclaredConstructor().newInstance();
      tProps = cfg.getPropertyGroup(PROP_THREAD_POOL_PREFIX, true);
      setBeanProps(tp, tProps);
      rsrcs.setThreadPool(tp);
      ...
    }
    ```

  - ```java
    // 启动调度器（初始化方法中）
    public void scheduleJob(String cron, String timeZone) {
        try {
            if (!this.scheduler.checkExists(this.jobDetail.getKey())) {
                this.scheduler.scheduleJob(this.jobDetail, this.createCronTrigger(cron, timeZone));
            }
            this.scheduler.start();// 启动调度线程
        } catch (SchedulerException var4) {
            SchedulerException ex = var4;
            throw new JobSystemException(ex);
        }
    }
    ```

  - ```java
    // 下次触发时间唤醒调度线程，减少调度线程的无效轮询
    notifySchedulerThread(trigger.getNextFireTime().getTime());
    ```

  - ```java
    // 调度器主线程
    // 获取截止时间在30s以内的触发器
    triggers = qsRsrcs.getJobStore().acquireNextTriggers(
      now + idleWaitTime, Math.min(availThreadCount, qsRsrcs.getMaxBatchSize()),
      qsRsrcs.getBatchTimeWindow());
    ...
    
    // 最近的一个触发器触发时间超过2ms时，先自旋
    while(timeUntilTrigger > 2) {
    ...
      now = System.currentTimeMillis();
      timeUntilTrigger = triggerTime - now;
    }
    
    // 任务封装为JobRunShell，并在执行线程池中执行
    qsRsrcs.getThreadPool().runInThread(shell)
    ```

#### 其他选型对比

|      框架       |      架构设计      |         分布式支持          | 分片任务 | 管理界面 |  依赖组件   |           适用场景            |
| :-------------: | :----------------: | :-------------------------: | :------: | :------: | :---------: | :---------------------------: |
|    **Timer**    |       单线程       |              ❌              |    ❌     |    ❌     |  JDK 内置   |  简单单机任务（不推荐生产）   |
| **Spring Task** |     基于线程池     | ❌（需结合分布式锁手动实现） |    ❌     |    ❌     | Spring 环境 | Spring 项目中的轻量级定时任务 |
|   **Quartz**    |  中心化（数据库）  |      ✅（基于数据库锁）      |    ❌     |    ❌     |   数据库    | 复杂调度需求（非分布式首选）  |
|   **XXL-JOB**   | 中心化（调度中心） |      ✅（基于调度中心）      |    ✅     |    ✅     |    MySQL    |    中小规模分布式任务调度     |
| **Elastic-Job** |   去中心化（ZK）   |         ✅（基于ZK）         |    ✅     |    ✅     |  ZooKeeper  |     大规模弹性分布式任务      |